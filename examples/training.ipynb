{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","COMMONROAD_GEOMETRIC_PATH = \"/content/drive/MyDrive/1 Universität/5. Semester/Autonomous Driving/code/\"\n","REPO_PATH = \"/content/drive/MyDrive/1 Universität/5. Semester/Autonomous Driving/code/project\"\n","\n","%matplotlib inline\n","\n","! /opt/bin/nvidia-smi"],"metadata":{"id":"aGGpfupIp7v9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"ydbej2cUmh9E"}},{"cell_type":"markdown","source":["## CommonRoad Geometric"],"metadata":{"id":"rY_lMz3QqDRY"}},{"cell_type":"code","source":["import torch\n","\n","# environment setup\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","%cd {COMMONROAD_GEOMETRIC_PATH}\n","\n","# install dependencies\n","!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric "],"metadata":{"id":"KdPsebmOqFnW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# commonroad-io installation\n","!pip install commonroad-io"],"metadata":{"id":"8HY4VM7gqPPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install commonroad geometric\n","!pip install -e ./commonroad-geometric-io/"],"metadata":{"id":"J4Q3gj0eqQ4d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Y5DVukg5qekN"}},{"cell_type":"code","source":["%cd {REPO_PATH}"],"metadata":{"id":"z6-r-gYrqcP5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from commonroad_geometric_io.common.io import list_files\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.data import Data"],"metadata":{"id":"gjGag0TAqdja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loader"],"metadata":{"id":"KXzke6vkmjbZ"}},{"cell_type":"markdown","source":["Create train loader and test loader by torch_geometric.loader "],"metadata":{"id":"1O4sQxNpeCjC"}},{"cell_type":"code","source":["data_dir = 'dataset'\n","dataset_paths = list_files(data_dir, file_type='pth', join_paths=True)\n","\n","def create_dataloader(dataset_path: str, mb_size: int) -> DataLoader:\n","            original_loader = torch.load(dataset_path)\n","            loader = DataLoader(\n","                original_loader,\n","                batch_size=mb_size,\n","                shuffle=True\n","            )\n","            return loader\n","\n","train_loader = create_dataloader(dataset_paths[-1], 64)\n","test_loader = create_dataloader(dataset_paths[1], 64)\n","#32 ,16 ,8\n","print('length_of_training_data', len(train_loader.dataset))\n","print('length_of_test_data', len(test_loader.dataset))\n"],"metadata":{"id":"Ez73yPBPnHAP","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"error","timestamp":1645198370968,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yunong WU","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13842083134237612170"}},"outputId":"82939fb2-6556-4fe8-cb52-b8ecc4b0bd63"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-957ebcba93e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommonroad_geometric_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'commonroad_geometric_io'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["# Model Architechture"],"metadata":{"id":"jAtGTbNkmjzO"}},{"cell_type":"markdown","source":["# Common utils"],"metadata":{"id":"4ko6zSfV-k9x"}},{"cell_type":"markdown","source":["Some utils used in our task"],"metadata":{"id":"3gtEfGZielTg"}},{"cell_type":"code","source":["import pickle\n","\n","\"\"\"\n","storage and load pickle file\n","\"\"\"\n","def save_variable(v, filename):\n","    f = open(filename, 'wb')\n","    pickle.dump(v,f)\n","    f.close()\n","    return filename\n","\n","def load_variable(filename):\n","    f = open(filename, 'rb')\n","    r = pickle.load(f)\n","    f.close()\n","    return r\n"],"metadata":{"id":"Q2OHqKfy-rkk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and Test utils"],"metadata":{"id":"61KJv2jcmkEk"}},{"cell_type":"markdown","source":["Utils used in model training and evaluation"],"metadata":{"id":"ks2N0k4Jevgm"}},{"cell_type":"code","source":["import numpy as np\n","from torch.nn import SmoothL1Loss, BCELoss\n","import joblib\n","\n","def train(data_loader, model, optimizer, epoch, loss_fn_cla, loss_fn_reg):\n","    \"\"\"\"\n","    Function for training a single epoch\n","    \"\"\"\n","    train_loss = []\n","    for idx, data in enumerate(data_loader):\n","        optimizer.zero_grad()\n","        x=data.x.cuda()   \n","        edge_index = data.edge_index.cuda()\n","        edge_attr = data.edge_attr.cuda()\n","        y=data.y.cuda()\n","\n","        cls_out, reg_out, en_cls_out, en_reg_out = model(x,edge_index,edge_attr)#.to(device)\n","        \n","        y_occupied_idx = y.gt(0.0)\n","        loss_cla = loss_fn_cla(cls_out, y_occupied_idx.float())\n","        \n","        loss_reg = loss_fn_reg(reg_out[y_occupied_idx], y[y_occupied_idx])\n","        loss = loss_cla + loss_reg*100\n","        \n","        loss.backward()\n","        optimizer.step()\n","        train_loss.append(loss.item())\n","        \n","        if (idx + 1) % 500 == 0:\n","            print(\"Train epoch: %d, iter: %d, loss_cla: %f\" % (epoch, idx, loss_cla))\n","            print(\"Train epoch: %d, iter: %d, reg_loss: %f\" % (epoch, idx, loss_reg*100))\n","\n","    return np.mean(train_loss)\n","\n","\n","def val(data_loader, model, epoch, loss_fn_cla, loss_fn_reg):\n","    \"\"\"\n","    Test(or evaluaction) function \n","    \"\"\"\n","    val_loss = []\n","    for idx, data in enumerate(data_loader):\n","        x=data.x.cuda()   \n","        edge_index = data.edge_index.cuda()\n","        edge_attr = data.edge_attr.cuda()\n","        y=data.y.cuda()\n","\n","        cls_out, reg_out, en_cls_out, en_reg_out = model(x,edge_index,edge_attr)#.to(device)\n","        \n","        y_occupied_idx = y.gt(0.0)\n","\n","        loss_cla = loss_fn_cla(cls_out, y_occupied_idx.float())\n","        loss_reg = loss_fn_reg(reg_out[y_occupied_idx], y[y_occupied_idx])\n","      \n","        loss = loss_cla + loss_reg*100\n","        \n","        val_loss.append(loss.item())\n","        \n","    return np.mean(val_loss)\n"],"metadata":{"id":"JBb87miUrYKN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example of training a reconstruction model"],"metadata":{"id":"Voz5fhP57PHE"}},{"cell_type":"code","source":["from model.traffic_representation_net import EGATConvs, EdgeConv, MLP, TrafficRepresentationNet\n","\n","model_f = TrafficRepresentationNet(in_node=2,in_edge=3,out_channels=8,num_heads=1,out_conv=8) \n","loss_cla = BCELoss()\n","loss_reg = SmoothL1Loss()\n","model_f = model_f.cuda()\n","\n","optimizer = torch.optim.Adam(model_f.parameters(), lr=0.001, weight_decay=0)\n","lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,0.96, last_epoch=-1)\n","\n","for epoch in range(50):   \n","  model_f.train()\n","  train_loss = train(train_loader, model_f, optimizer, epoch, loss_cla, loss_reg)\n","\n","  model_f.eval()\n","  val_loss = val(test_loader, model_f, epoch, loss_fn_cla=loss_cla, loss_fn_reg=loss_reg)\n","  lr_scheduler.step()\n","  print(\"Train epoch: %d, lr: %f, loss: %f\" % (epoch, lr_scheduler.get_lr()[0], train_loss))\n","  print(\"Test epoch: %d, loss: %f\" % (epoch, val_loss))\n","\n","#save model in model_dir\n","# model_dir = ''\n","# torch.save(model_f, model_dir)"],"metadata":{"id":"hin7TJYG7OVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_loss_en_dim(min_model_dir, dim_list, epochs):\n","  \"\"\"\n","  Train model with different encoder output dimenstions \n","  and get corresponding val_loss \n","\n","  min_model_dir: model path\n","  dim_list: encoder output dimenstion\n","\n","  return val. loss\n","  \"\"\"\n","  vals_loss = []\n","  for idx, dim in enumerate(dim_list):\n","    print('dim',dim)\n","    model_f = TrafficRepresentationNet(in_node=2,in_edge=3,out_channels=8,num_heads=1,out_conv=dim) \n","    loss_cla = BCELoss()\n","    loss_reg = SmoothL1Loss()\n","    model_f = model_f.cuda()\n","\n","    optimizer = torch.optim.Adam(model_f.parameters(), lr=0.001, weight_decay=0)\n","    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,0.96, last_epoch=-1)\n","\n","    vals = []\n","    for epoch in range(epochs):   \n","      model_f.train()\n","      train_loss = train(train_loader, model_f, optimizer, epoch, loss_cla, loss_reg)\n","\n","      model_f.eval()\n","      val_loss = val(test_loader, model_f, epoch, loss_fn_cla=loss_cla, loss_fn_reg=loss_reg)\n","      vals.append(val_loss)\n","      lr_scheduler.step()\n","      print(\"Train epoch: %d, lr: %f, loss: %f\" % (epoch, lr_scheduler.get_lr()[0], train_loss))\n","      print(\"Test epoch: %d, loss: %f\" % (epoch, val_loss))\n","    \n","    min_save_dir = min_model_dir + str(idx) + '_' + str(dim) + '.pth'\n","    torch.save(model_f, min_save_dir)\n","    vals_loss.append(vals)\n","\n","  return vals_loss"],"metadata":{"id":"lqmgg2rarvqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PCA "],"metadata":{"id":"76F0sDRh72DT"}},{"cell_type":"markdown","source":["Utils of PCA analysis"],"metadata":{"id":"atLSc5V9fLBV"}},{"cell_type":"code","source":["def get_en_out(data_loader, model):\n","  \"\"\"\n","  Get the encoder outputs of the given data from the model\n","  \"\"\"\n","  flag = 1\n","  for idx, data in enumerate(data_loader):\n","    #if idx%5==0: \n","      x=data.x.cuda()   \n","      edge_index = data.edge_index.cuda()\n","      edge_attr = data.edge_attr.cuda()\n","      y=data.y.cuda()\n","      cls_, reg_, en_cls_out, en_reg_out = model(x,edge_index,edge_attr)#.to(device)\n","        \n","      en_out = torch.cat((en_cls_out,en_reg_out),-1)\n","      if flag:\n","        en_outs = en_out\n","        flag = 0\n","      else:\n","        en_outs = torch.cat((en_outs,en_out),0)\n","\n","  return en_outs\n","\n","def vis_pca_heatmap(pca_model, en_outs):\n","    \"\"\"\"\n","    visualize pca heatmap\n","    \"\"\"\n","    X_new = pca_model.transform(en_outs)\n","    x = X_new[:,0]\n","    y = X_new[:,1]\n","\n","    xy = np.vstack([x,y])\n","    z = gaussian_kde(xy)(xy)\n","    z = preprocessing.maxabs_scale(z,axis=0, copy=True)\n","\n","    idx1 = z.argsort()\n","    x2, y2, z2 = x[idx1], y[idx1], z[idx1]\n","\n","    fig2, ax2 = plt.subplots()\n","\n","    ax2.set_xlabel('PCA_dim1', fontsize=10)\n","    ax2.set_ylabel('PCA_dim2', fontsize=10)\n","\n","    img = ax2.scatter(x2, y2, c=z2, s=0.5, edgecolors=\"none\",cmap=\"inferno\")#cmap='Reds')\n","    cbar = plt.colorbar(img, ax=ax2)\n","\n","    plt.grid()\n","\n","    plt.show()"],"metadata":{"id":"q1y-Jpd27Isy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load model and get encoder output"],"metadata":{"id":"Po-V01BN8k_k"}},{"cell_type":"code","source":["model_dir1 = f'{REPO_PATH}/min_dim_model/128.pth'\n","model_l_ = torch.load(model_dir1)\n","\n","en_outs = get_en_out(test_loader, model_l_)\n","en_outs_n = en_outs.cpu().detach().numpy() "],"metadata":{"id":"h6z5OWdY8j6J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2D PCA decompostion on encoder output "],"metadata":{"id":"v_9lDZmp9nKj"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import joblib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import gaussian_kde\n","from sklearn import preprocessing\n","\n","pca2 = PCA(n_components=2)\n","pca2.fit(en_outs_n)\n","\n","print('n_components', pca2.n_components)\n","print('explained_variance_ratio_', pca2.explained_variance_ratio_)\n","print('explained_variance_', pca2.explained_variance_)\n","print('get_params',pca2.get_params)\n","\n","#save PCA model in pca_dir\n","# pca_dir = ''\n","# joblib.dump(pca2, pca_dir+'pca2.m')"],"metadata":{"id":"p-dV_-Ek9YQc"},"execution_count":null,"outputs":[]}]}